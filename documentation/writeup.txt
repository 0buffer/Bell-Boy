Hi all.

This is quite a long post but I would like to document the work I have done on a new Pi-powered device used to measure how tower bell ringers ring bells and to enable more effecting training of new bell ringers

Tower bell ringing is quite an art and needs lots of practice to do well.  It is true that, fundamentally, you are just pulling on a rope (called a sally in the parlance) but you have to pull just hard enough to allow your bell to be properly controlled and accurately enough so that you are in time with all the other ringers in your band.

To give non-bell-ringers an idea of what's involved, the bell starts with its open end down.  The bell is then "rung up" through sucessive pulls on the sally each pull taking the open end of the bell higher until the open end can point straight up (at "balance"), the bell is taken a bit beyond the balance point (about 10 degrees) and the arrangement is such that a wooden piece (called a stay) rests against another piece of wood called a slider and the bell can then rest at the point (and the ringer can take hands off the sally).  The bell is now "up" and is ready to be rung.

To ring the bell, the ringer pulls the sally, taking the bell off the stay, through the balance point and the bell then falls by gravity and rises to the other side.  The bell ringer then controls the rise of the bell by using the sally to check the speed of the bell so that it just about reaches the balance point and then continues the pull to take the bell down again.    The arrangement is such that the slider allows the bell to go slightly beyond the balance point on each half of the stroke.

A nice diagram showing the arrangement is here: https://www.bellsofstmarys.org.uk/information/bell-ringing

Part of the problem in teaching someone to ring tower bells is that it is quite difficult to tell what a learner is doing, pulling to hard, too soft, too early or too late, not allowing the bell to rise to the balance point and not pulling hard enough so that the bell can actually rise to the balance point on the next half stroke.  Even if you are a quite experienced ringer, just looking at someone and how the rope is moving is often not enough to understand what someone is doing right or wrong.

A case in point, I tried learning to ring tower bells a few years ago but stopped (mostly because I was rubbish and because I thought I was not progressing well enough).

An article in "The Ringing World" magazine last December was pointed out to me in January.  This describes the author's efforts in making and trying to get others to make a "pullometer" to measure the how hard the sally is being pulled.

www.jaharrison.me.uk/New/Articles/PullometerChallenge.pdf

This sort of problem is exactly up my street and the prize on offer (see article) would make the challenge even sweeter.  I quickly thought through two possible solutions, one using a camera to measure how the bell was rotating and one using an accelerometer/gyro device.  The former was quickly dismissed as I watched a youtube video of someone doing something similar using openCV to analyse a rotating image (exactly what I was going to do) - the resolution and accuracy did not seem good enough.

I had played with accelerometers before on (mostly on Sunxi devices) and a quick proof of concept using an arduino, an MPU6050 accelerometer/gyro and a bluetooth transciever glued together with some code from i2cdevlib (see github) showed what I thought to be quite remarkable data.  You could clearly see strokes where the ringer was ringing too hard and too soft and you could even see the effect on the bell sounding (there was a big jump in the acceleration of the bell and quite a lot of vibration).  This was enough to convince me that the accelerometer solution was a good one.

It is a long journey from a proof of concept to a device capable of being used in the real world and much of my free time since January 2017 has been spent refining the software and improving things so that the end result is a device that can be easily constructed and used by anyone.

The front end
The first attempt I had to create a front end was .NET based.  This still used raw data pumped from an arduino over bluetooth and rejigged it for display.  Because of various problems I had with this version of the front end, with Bluetooth range and because I wanted the front end to be compatible with all types of devices, I decided after about a month to do this the right way and get the front end browser-based.

The best way to achieve this was to use a battery powered Pi attached to the bell to create its own wifi network and serve the web page and data to the device which would use javascript to present things to the user in a friendly manner.

HTML5 was a must because canvas elements enable real-time graphics to be displayed.  Data also needed to be pumped to the browser in real-time and for that I would need a technology I had never used before, websockets.

The resulting front end is some pretty simple HTML and a pretty big chunk of Javascript that takes care of pulling data from the device and displaying to the user.

A sample of the front end is here:

http://www.thebudds.net/

This sample is not connected to a bell so the record and live view functionality does not do anything but you can still view sample recordings (which were taken from a real bell).  Just click on the cloud download button, select one of the recordings, force a calibration (click the cog icon and click calibrate) and then click play. 

The back end
The Pi on which the back end runs is configured in a reasonably standard hostapd configuration to create its own wifi network.  You can see how I have managed the configuration from the project github page (see below), the script is called "setupBB.sh" and takes a stock Arch image and installs and configures everything needed.

On a point of detail,  I tried a few different webserver/websocket servers  but settled on pywebsockets (see github) as it had a nice structure and enabled me to easily plug in websocket handler code needed to calculate bell position, velocity and acceleration and to serve the result over a websocket connection to the browser.

Data from the accelerometer
This part of the project, despite earlier proof-of-concept success was a nightmare.  

I initially used the very common MPU6050s IMU devices which are cheap easily available, well characterised and have loads of code already written for them.

The code out there, whilst incredibly useful, was not fully usable because of one problem: the traditional ways of converting the data pulled from the MPU6050 accelerometers/gyros relied on there being not too much rotational acceleration.  For most of the stroke of the bell its rotational acceleration is large and the available code could not split out the tangential acceleration created by the pull on the rope and by gravity acting on the bell.

Of course, I could have ignored the fact that gravity effects and pull were mixed together as for most of the time the bell is under the control of the ringer, it is moving slowly and so the unwanted effects were quite small. The mixing was, however, annoying and meant that there were parts of the pull when the bell was picking up speed where you could not quite tell what the ringer was doing.

Another possible solution was to calibrate the system with a "minimal pull" and deduct that from real measurements from a learner.  Trials showed that achieving a minimal pull is actually quite hard.  A bell pulled off stand with as little force as possible will not rise all the way back up at the other side and so a mimimal pull would have to be conducted both from stand at handstroke and stand at backstroke.  I really wanted the system to be easy to use and this level of calibration was not attractive.

I could also have built a (computer) model as to how a bell would behave.  The bell system is quite simple, being just one dimensional rotation and I really thought it would be easy to work out what was gravity and what was pull algorithmically.  The basic equations describing the bell system are pretty well known (see here for an example) https://www.cl.cam.ac.uk/~fhk1/Bells/equations.pdf.  The equations tell us (broadly) that the angular acceleration of a bell in free motion due to gravity is just a constant multiplied by the sin of the angle the bell is at.

I spent about four months working around this, the difficulty is that to work out what angle the bell is at the accelerometers on the device need to know which way is down.  For most applications (tablets, drones, balancing robots etc) this is done by working out the pull of gravity on each of the three accelerometers and then doing some trigonometry.  The problem was that the pull of gravity was being "corrupted" by the motion of the bell so I was faced with a chicken and egg problem.  I could not remove the effect of gravity from the motion of the bell until I knew the angle the bell was at and I could not work out the angle of the bell unless I knew the effect of gravity.

After strugging with this for a while, I eventually gave up and tried a more complex solution that I identified early on but did not really want to go for because of the complexity.  The solution involved using two MPU6050 devices each mounted on opposite sides to the axle of the bell along the same diameter.  The accelerometers were mounted such that gravity would pull in the same direction on each of them but that tangential acceleration would pull in opposite directions.  Separating out gravity was then case of just adding the two accelerometer readings (and dividing by two) to have a gravity-only signal and subtracting the two readings (and dividing by two) to have a tangential acceleration-only signal.  This worked well but there were quite a few thngs to look at:

(a)	MPU6050s communicate over i2c I would have to connect the i2c devices over a cable to the Pi.  I2c does not like being connected over long cables (so I hear). Some experimentation was required on reliability of i2c. I tried first with ethernet cable and then with two twisted pair telephone cable and found that i2c worked perfectly well over 750mm cables (two of them so total bus length of 1.5m).  I even boosted the i2c clock to 600mHz (way out of spec for the MPU6050s) and it still worked well.  I examined the i2c clock and data signals using an oscilloscope and whilst there was a bit of clock edge rounding and a bit of ringing, it really didn't look too bad even at 600Mhz.  Test passed.  Note that each of the MPU6050s have 2.2k ohm i2c pull ups and the Pi has 1.8 k ohm pull ups so the whole bus was pulled up massively out of spec (680 ohms or so) - it still worked reliably. 

(b)	The two MPU6050s were running on their internal clocks, these are quite accurate but not perfectly so and inevitably, one MPU6050 is producing data at a slightly higher rate than the other.  The worse case I saw was with a 50hz sample rate, one additional sample was being produced by the faster running MPU6050 ever 10 or so seconds.  The MPU6050 has 4 different internal clock sources so choosing which clock source was being used by each of them could reduce the imbalance a lot but not perfectly (with this sort of tuning I could get down to one additional sample per minute or two).  This was not good enough for me as the effect of these additional samples could be quite significant - at its fastest point the bell is moving at around 450 degrees/sec so there would be an error of around 9 degrees (at a 50hz sample rate) for each additional sample.  The solution I adopted was quite simple in the end, the MPU6050s have a fifo and I could see how many samples were in the fifo awaiting being pulled over i2c by the Pi, so I just detected when there were more samples awaiting processing in one of the MPU6050s and did a dummy read on that MPU6050.

(c) The last problem was more challenging.  For the two sensor solution to work well, the two sensors had to be pretty accurately positioned in terms of orientation and distance from the axle of the bell. Mathematical adjustments could be easily applied of course but I could not find a way to adjust for orientation in a way that was automatic and required minimal user calibration. Adjusting for differences in the distance from the axle could be calibrated out in an automatic(ish) fashion but there would have to have been quite a few calibration rings of the bell so that the Pi could do some maths to work out where each sensor was placed.

(d) the device became much harder to construct (and I wanted a device that could be made by anyone).  I was not really interested in making the devices myself but realised that if I was going to continue with this project that's exactly what I would have to do - I investigated product certification and (with help from Pi Towers) was put in touch with a helpful chap who confirmed that the costs of certification were likely to be prohibitive for this small scale.

Whilst pondering (c) and (d), I came to a realisation that I could go back to the single sensor solution with what I had learned from the dual sensor solution but it would require some trickery.

For those that don't know the cheap IMU sensors you can buy from anywhere for a few pounds or less have three gyroscopes and three accelerometers each pointing on one of the x, y and z axes.  The gyroscopes are accurate in the short term but drift so are less accurate in the long term (a second or two has a measureable drift).  The accelerometers produce a very noisy signal but when averaged over many samples (50-100 or so) produce quite accurate results.  The gyros are thus accurate in the short term but inaccurate in the long term and the accelerometers are inaccurate in the short term but accurate in the long term (after much averaging).

Much work has been done by many people cleverer than me to combine accelerometer and gyro signals in such a way that orientation information (i.e. which way the device is pointing) can be created using the strengths of each of the sensor types whilst avoiding their weaknesses.  Some quite marvellous results can be obtained by different filters and the one I was using is known as the Kalman filter.

There are lots of online explanations of the Kalman filter but it is quite a complicated thing even though its does not require much code to implement.  The best explanation I found was here (it talks to something called the Extended Kalman Filter but starts with an explanation of the basic Kalman filter):

https://home.wlu.edu/~levys/kalman_tutorial/

The results on a single sensor were still not good enough for me.  I tried adjusting the Kalman filter to accomodate these fixes (basically by injecting a new measurement with a vastly reduced measurement noise parameter at the relevant point) but the filter (being an almost magical dynamic recalibration thing) did not take too kindly to this.  I am sure that someone with more brainpower in this area could produce a version of the Kalman filter that could accomodate what I was trying to do but I needed to look elsewhere.

When I came back to this in December last year, I decided to try another chip.  A trial using a FXOS8700 and FXAS21002 on a single breakout board (https://www.adafruit.com/product/3463) was improved but the most improvement came from using extended Kalman filter from here: https://github.com/hhyyti/dcm-imu.  This was really transformative and I was getting sub-degree accurate data.  With this data, I could adjust for gravity and gravitational effects properly and just display the pull from the rope.

Here is a little image of the data.  The blue line shows the raw data from the device.  It is mostly sinusoidal.  The yellow(ish) line shows the acceleration of the bell after adjustment for gravity effects.  It is nearly flat (the big spikes are caused by the bell clapper) but at the ends you can see that the line is slightly above the axis (left) and slightly below the axis (right).  This is caused by the pull on (and of) the rope.

Overall, the results from a single sensor approach were now comparable to the two sensor solution but the device is now much easier to construct .  I nonetheless think that for anyone that wants to do a fuller scientific or engineering analysis of the bell system, the two sensor method is best (I have retained some experimental code in the Project GitHub if anyone wants to use it (https://github.com/BBUK/Bell-Boy) and also the best way I found of mounting the sensors was by using a bar clamp - see the pictures of the various prototype sensors linked below, the final one is the orange box).  

Power
Back to something simpler!  The Pi had to be battery powered and the user needed to have a way of switching the device on and off.  Even though power-off SD card corruption seems to be much rarer now than with the first Pi and kernel, I still don't like just removing power from the Pi and would rather have a controlled shutdown followed by a power-off.

Early versions of the device used a LiPo and one of the brilliant Adafruit LiPo boards (PowerBoost 1000C).  I decided, however, that if anyone else wanted to build one of these devices then 





 
